{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNZv1L1uLfBapT0DIo3YEym",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/avinwu/projects/blob/main/Marketing_Lead_Scoring_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What is Marketing Lead Scoring Model\n",
        "A Marketing Lead Scoring Model is a systematic approach used to rank potential customers (leads) based on their likelihood to convert into paying customers. This model assigns scores to leads by evaluating their behavior, demographic information, and engagement with the company's marketing efforts.\n",
        "Key factors considered include:\n",
        "- **Demographic Data**: Attributes such as age, job title, industry, and company size.\n",
        "- **Behavioral Data**: Actions taken by the lead, such as website visits, email opens, content downloads, and social media interactions.\n",
        "- **Engagement Metrics**: Frequency and recency of interactions with the brand.\n",
        "The scores help the marketing and sales teams prioritize leads, focusing their efforts on those most likely to convert. This not only improves sales efficiency but also enhances marketing strategies by identifying high-value leads.\n",
        "\n",
        "For example, a lead scoring model might assign higher scores to leads who visit the pricing page multiple times and attend webinars, compared to those who only download a single whitepaper. By integrating such a model into a CRM system, businesses can automate the lead qualification process, ensuring timely and personalized follow-ups, ultimately increasing the conversion rate and sales productivity.\n",
        "\n",
        "## Marketing Lead Scoring Model\n",
        "Creating a marketing lead scoring model involves several steps: collecting and preprocessing data, exploring and analyzing the data, building and validating the model, and deploying it. Below is a detailed outline for such a project, including sample code snippets.\n",
        "\n",
        "## Project Outline for Marketing Lead Scoring Model\n",
        "1. **Define the Objective**\n",
        "  - **Objective**: Develop a model to score marketing leads based on their likelihood to convert into customers.\n",
        "  - **Outcome**: A lead scoring system that ranks leads, helping the marketing team prioritize their efforts.\n",
        "\n",
        "2. **Data Collection**\n",
        " - **Sources**: CRM data, web analytics, email campaign responses, social media interactions.\n",
        "  - **Features**: Lead demographics (age, location, job title), engagement metrics (email opens, website visits), firmographics (company size, industry), etc.\n",
        "3. **Data Preprocessing**\n",
        "  - **Data Cleaning**: Handle missing values, remove duplicates.\n",
        "  - **Feature Engineering**: Create new features (e.g., engagement score), normalize/scale numerical features, encode categorical features.\n",
        "4. **Exploratory Data Analysis (EDA)**\n",
        "  - **Descriptive Statistics**: Summary statistics, distribution plots.\n",
        "  - **Correlation Analysis**: Correlation matrix to identify relationships between features.\n",
        "  - **Visualizations**: Histograms, box plots, scatter plots.\n",
        "5. **Model Building**\n",
        "  - **Train/Test Split**: Split the data into training and testing sets.\n",
        "  - **Model Selection**: Choose algorithms (e.g., Logistic Regression, Random Forest, XGBoost).\n",
        "â€¢\tModel Training: Train the models on the training set.\n",
        "6. **Model Evaluation**\n",
        "  - **Metrics**: Accuracy, precision, recall, F1 score, AUC-ROC.\n",
        "  - **Validation**: Cross-validation, confusion matrix.\n",
        "7. **Model Deployment**\n",
        "  - **API Creation**: Create an API to serve the model.\n",
        "  - **Integration**: Integrate the model with the CRM system.\n",
        "  - **Monitoring**: Track the performance and retrain as necessary.\n",
        "\n"
      ],
      "metadata": {
        "id": "DFo7aPXfzBIv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing"
      ],
      "metadata": {
        "id": "WyGAUSGT1J7F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Load data\n",
        "data = pd.read_csv('leads.csv')\n",
        "\n",
        "# Define feature columns and target variable\n",
        "feature_cols = ['age', 'location', 'job_title', 'email_opens', 'website_visits', 'company_size', 'industry']\n",
        "target_col = 'converted'\n",
        "\n",
        "# Split data into features and target\n",
        "X = data[feature_cols]\n",
        "y = data[target_col]\n",
        "\n",
        "# Define preprocessor\n",
        "numeric_features = ['age', 'email_opens', 'website_visits', 'company_size']\n",
        "categorical_features = ['location', 'job_title', 'industry']\n",
        "\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features)])\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Apply preprocessing\n",
        "X_train = preprocessor.fit_transform(X_train)\n",
        "X_test = preprocessor.transform(X_test)"
      ],
      "metadata": {
        "id": "J64B5qEt0Ntj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Build/Evaluate"
      ],
      "metadata": {
        "id": "Cwa0Xzck0vdV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "\n",
        "# Train the model\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "y_prob = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Evaluate the model\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(f'AUC-ROC: {roc_auc_score(y_test, y_prob)}')"
      ],
      "metadata": {
        "id": "i3akbiLK0uyX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Deployment (Flask)"
      ],
      "metadata": {
        "id": "pHCNsoCB07p8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, request, jsonify\n",
        "import joblib\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Save the model\n",
        "joblib.dump(model, 'lead_scoring_model.pkl')\n",
        "joblib.dump(preprocessor, 'preprocessor.pkl')\n",
        "\n",
        "# Load the model\n",
        "model = joblib.load('lead_scoring_model.pkl')\n",
        "preprocessor = joblib.load('preprocessor.pkl')\n",
        "\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    data = request.json\n",
        "    df = pd.DataFrame(data)\n",
        "    X = preprocessor.transform(df)\n",
        "    scores = model.predict_proba(X)[:, 1]\n",
        "    return jsonify({'scores': scores.tolist()})\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(debug=True)"
      ],
      "metadata": {
        "id": "n5jhNkMa05pb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Monitoring and Retraining\n",
        "Create scripts to periodically check model performance and retrain with new data if necessary. This could involve setting up cron jobs or using cloud-based ML platforms.\n",
        "\n",
        "## Conclusion\n",
        "This project outline provides a structured approach to building a marketing lead scoring model. By following these steps and using the provided code snippets, you can develop a robust system that helps prioritize marketing efforts and improves lead conversion rates."
      ],
      "metadata": {
        "id": "NZH5-i5s1Avv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "gdWyNm7m014W"
      }
    }
  ]
}