{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15400c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, sys\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from lxml import html\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45761419",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_zillow_listings(pid, nIdx, url, file_dir):\n",
    "    now = datetime.now()  # current date and time\n",
    "    date_time = now.strftime(\"%m/%d/%Y, %H:%M:%S\")\n",
    "\n",
    "    out_file_bldg = file_dir + 'zillow_listings_dtl_out_blgds_1.csv'\n",
    "    out_file_othr = file_dir + 'zillow_listings_dtl_out_othrs_1.csv'\n",
    "\n",
    "    req_headers = {\n",
    "        'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',\n",
    "        'Connection': 'close',\n",
    "        'Host': 'www.zillow.com',\n",
    "        'Accept': 'text/html, application/xhtml+xml, application/xml; q=0.9, */*; q=0.8',\n",
    "        'accept-encoding': 'gzip, deflate, br',\n",
    "        'accept-language': 'en-US,en;q=0.8',\n",
    "        'upgrade-insecure-requests': '1',\n",
    "        'Cache-Control': 'max-age=0',\n",
    "        'Cookie': 'AWSALB=update_your_cookie_here',\n",
    "        'user-agent': 'Mozilla/2.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/61.0.3163.100 Safari/537.36'\n",
    "    }\n",
    "    req_headers['Referer'] = url\n",
    "    # print(response.status_code)\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, headers=req_headers)\n",
    "        # print(response.status_code)\n",
    "        resp_code = response.status_code\n",
    "        resp_text = response.text\n",
    "\n",
    "        if 'name=\"robots\"' in resp_text:\n",
    "            print(f\"[DEBUG] CAPTCHA\")\n",
    "            sys.exit()\n",
    "\n",
    "        soup = BeautifulSoup(resp_text, 'html.parser')\n",
    "        # print(soup.title)\n",
    "\n",
    "        script = soup.find('script', {'id': '__NEXT_DATA__',\n",
    "                                      'type': 'application/json'}).text\n",
    "        dict_1 = json.loads(script)\n",
    "        sPage = dict_1['page'][1:]  # get rid of the leading \"/\"\n",
    "\n",
    "        if sPage == 'building':\n",
    "            # Get Listing Details for buildings\n",
    "            get_lstng_dtl_bldng(pid, nIdx, url, out_file_bldg, dict_1, date_time)\n",
    "        else:\n",
    "            # Get Listing Details for others\n",
    "            get_lstng_dtl_other(pid, nIdx, url, out_file_othr, dict_1, date_time)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[FAILURE] [{date_time}] PID# {nIdx}: {url} [ERROR] {e}\")\n",
    "        return\n",
    "\n",
    "    # debug print\n",
    "    # for k in dctPdtl: print(\"{0:25} {1}\".format(k, dctPdtl[k]))\n",
    "\n",
    "def get_lstng_dtl_bldng(pid, nIdx, url, out_file, dict_1, date_time):\n",
    "    dctPdtl = {}\n",
    "    dctPdtl['pid'] = pid\n",
    "\n",
    "    dict_2 = dict_1['props']['pageProps']['initialData']['building']\n",
    "\n",
    "    lstKeys = ['zpid', '__typename', 'buildingType', 'streetAddress', 'latitude', 'longitude', 'city', 'state',\n",
    "               'zipcode',\n",
    "               'county', 'buildingName', 'buildingPhoneNumber', 'buildingAttributes', 'amenitySummary', 'homeTypes']\n",
    "\n",
    "    for l in lstKeys:\n",
    "        if l in dict_2.keys():\n",
    "            dctPdtl[l] = dict_2[l]\n",
    "        else:\n",
    "            dctPdtl[l] = ''\n",
    "\n",
    "    lstUnits = dict_2['ungroupedUnits']\n",
    "\n",
    "    # lstUnitPID, lstUnitNum, lstUnitURL, lstUnitTyp, lstUnitLstTyp = [], [], [], [], []\n",
    "    lstUnitPID, lstUnitURL = [], []\n",
    "\n",
    "    for u in lstUnits:\n",
    "        lstUnitPID.append(u['zpid'])\n",
    "        # lstUnitNum.append(u['unitNumber'])\n",
    "        lstUnitURL.append(u['hdpUrl'])\n",
    "        # lstUnitTyp.append(u['__typename'])\n",
    "        # lstUnitLstTyp.append(u['listingType'])\n",
    "\n",
    "    dctPdtl['unit_pid'] = lstUnitPID\n",
    "    # dctPdtl['unit_num'] = lstUnitNum\n",
    "    dctPdtl['unit_url'] = lstUnitURL\n",
    "    # dctPdtl['unit_typ'] = lstUnitTyp\n",
    "    # dctPdtl['unit_lst_typ'] = lstUnitLstTyp\n",
    "\n",
    "    row = list(dctPdtl.values())\n",
    "    df = pd.DataFrame(row).T\n",
    "    df.to_csv(out_file, mode='a', index=False, header=False)\n",
    "\n",
    "    print(f\"[SUCCESS] [{date_time}] PID# {nIdx}: {url}\")\n",
    "\n",
    "\n",
    "def get_lstng_dtl_other(pid, nIdx, url, out_file, dict_1, date_time):\n",
    "    # Dictionary to hold all the fields to be extracted for this pid.\n",
    "    dctPdtl = {}\n",
    "    dctPdtl['pid'] = pid\n",
    "\n",
    "    s = dict_1['props']['pageProps']['gdpClientCache']\n",
    "    dict_2 = json.loads(s)\n",
    "    key_dict_2 = list(dict_2.keys())[0]\n",
    "    dict_3 = dict_2[key_dict_2]\n",
    "    dict_4 = dict_3['property']\n",
    "\n",
    "    lstKeys = \\\n",
    "        ['zpid', 'homeType', 'streetAddress', 'city', 'state', 'zipcode', 'latitude', 'longitude', 'county', 'country',\n",
    "         'parcelId', 'bedrooms', 'bathrooms', 'zestimate', 'rentZestimate', 'yearBuilt', 'livingArea',\n",
    "         'livingAreaValue',\n",
    "         'livingAreaUnitsShort', 'lotSize', 'lotAreaValue', 'lotAreaUnits', 'currency', 'taxAssessedValue',\n",
    "         'taxAssessedYear',\n",
    "         'monthlyHoaFee', 'propertyTaxRate', 'lastSoldPrice', 'dateSoldString', 'parentRegion', 'neighborhoodRegion',\n",
    "         'building', 'boroughId', 'providerListingID', 'hdpUrl']\n",
    "\n",
    "    for l in lstKeys:\n",
    "        if l in dict_4.keys():\n",
    "            dctPdtl[l] = dict_4[l]\n",
    "        else:\n",
    "            dctPdtl[l] = ''\n",
    "\n",
    "    lstKeys = \\\n",
    "        ['appliances', 'heating', 'cooling', 'fireplaceFeatures', 'fireplaces', 'flooring', 'levels', 'stories',\n",
    "         'storiesTotal', 'ownershipType', 'parkingCapacity', 'parkingFeatures', 'otherParking', 'roofType', 'rooms',\n",
    "         'propertyCondition', 'constructionMaterials', 'exteriorFeatures', 'architecturalStyle', 'waterView',\n",
    "         'waterViewYN', 'windowFeatures', 'hasAdditionalParcels', 'hasPetsAllowed', 'hasRentControl', 'hasHomeWarranty',\n",
    "         'isNewConstruction', 'hasAssociation', 'hasAttachedGarage', 'hasAttachedProperty', 'hasCooling', 'hasCarport',\n",
    "         'hasElectricOnProperty', 'hasFireplace', 'hasGarage', 'hasHeating', 'hasLandLease', 'hasOpenParking',\n",
    "         'hasSpa', 'hasPrivatePool', 'hasView', 'hasWaterfrontView', 'elementarySchool', 'elementarySchoolDistrict']\n",
    "\n",
    "    dict_5 = dict_4['resoFacts']\n",
    "\n",
    "    for l in lstKeys:\n",
    "        if l in dict_5.keys():\n",
    "            dctPdtl[l] = dict_5[l]\n",
    "        else:\n",
    "            dctPdtl[l] = ''\n",
    "\n",
    "    row = list(dctPdtl.values())\n",
    "    df = pd.DataFrame(row).T\n",
    "    df.to_csv(out_file, mode='a', index=False, header=False)\n",
    "\n",
    "    print(f\"[SUCCESS] [{date_time}] PID# {nIdx}: {url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159cd0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main call\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    inp_dir, out_dir = '../data_inp/', '../data_out/'\n",
    "    inp_file = inp_dir + 'zillow_listings_url_inp_2.csv'\n",
    "    #out_file = out_dir + 'zillow_listings_dtl_out.csv'\n",
    "    nSleep=5\n",
    "\n",
    "    df = pd.read_csv(inp_file)\n",
    "    dct = df.to_dict('index')\n",
    "    #lstKeys = df.to_dict('index').keys()\n",
    "\n",
    "    for nIdx in dct.keys():\n",
    "        #nURLIdx += 1\n",
    "        pid = dct[nIdx]['property_id']\n",
    "        url = dct[nIdx]['url']\n",
    "\n",
    "        get_zillow_listings(pid, nIdx, url, out_dir)\n",
    "\n",
    "        # nSleep += 2\n",
    "        # if nSleep>=60: nSleep=10 #Reset sleep time back to 10seconds\n",
    "        time.sleep(nSleep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889d09b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
